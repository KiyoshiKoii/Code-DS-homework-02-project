{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "160480ee",
   "metadata": {},
   "source": [
    "# Khám Phá Dữ Liệu: Phân Tích Rời Bỏ Khách Hàng Thẻ Tín Dụng\n",
    "\n",
    "## Mục tiêu\n",
    "- Tải và kiểm tra bộ dữ liệu BankChurners sử dụng NumPy\n",
    "- Hiểu cấu trúc dữ liệu và các đặc trưng\n",
    "- Thực hiện phân tích khám phá dữ liệu\n",
    "- Xử lý giá trị thiếu và tiền xử lý dữ liệu\n",
    "- Chuẩn bị dữ liệu cho trực quan hóa và mô hình hóa\n",
    "\n",
    "## Câu hỏi nghiên cứu:\n",
    "Trước khi đi sâu vào dữ liệu, chúng ta đặt ra một số câu hỏi để định hướng phân tích:\n",
    "1. **Chất lượng dữ liệu:** Dữ liệu có sạch không? Có giá trị thiếu hay ngoại lai nào đáng lo ngại không?\n",
    "2. **Cấu trúc khách hàng:** Tỷ lệ khách hàng rời bỏ là bao nhiêu? Có sự mất cân bằng lớp nghiêm trọng không?\n",
    "3. **Đặc điểm nhân khẩu học:** Khách hàng của ngân hàng chủ yếu thuộc nhóm tuổi, giới tính và trình độ học vấn nào?\n",
    "4. **Mối quan hệ:** Có mối tương quan nào rõ ràng giữa các biến số (ví dụ: hạn mức tín dụng và thu nhập) ngay từ cái nhìn đầu tiên không?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1074c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import các thư viện cần thiết\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Đặt seed ngẫu nhiên để tái lập kết quả\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33425dd0",
   "metadata": {},
   "source": [
    "## 1. Tải Bộ Dữ Liệu Sử Dụng NumPy\n",
    "\n",
    "Chúng ta sẽ tải file CSV sử dụng hàm genfromtxt của NumPy để đọc dữ liệu vào mảng có cấu trúc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a1910d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tên các cột:\n",
      "0: CLIENTNUM\n",
      "1: Attrition_Flag\n",
      "2: Customer_Age\n",
      "3: Gender\n",
      "4: Dependent_count\n",
      "5: Education_Level\n",
      "6: Marital_Status\n",
      "7: Income_Category\n",
      "8: Card_Category\n",
      "9: Months_on_book\n",
      "10: Total_Relationship_Count\n",
      "11: Months_Inactive_12_mon\n",
      "12: Contacts_Count_12_mon\n",
      "13: Credit_Limit\n",
      "14: Total_Revolving_Bal\n",
      "15: Avg_Open_To_Buy\n",
      "16: Total_Amt_Chng_Q4_Q1\n",
      "17: Total_Trans_Amt\n",
      "18: Total_Trans_Ct\n",
      "19: Total_Ct_Chng_Q4_Q1\n",
      "20: Avg_Utilization_Ratio\n",
      "21: Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\n",
      "22: Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\n",
      "\n",
      "Kích thước bộ dữ liệu: (10127, 23)\n",
      "Số lượng mẫu: 10127\n",
      "Số lượng đặc trưng: 23\n"
     ]
    }
   ],
   "source": [
    "# Tải dữ liệu sử dụng NumPy\n",
    "data_path = '../data/raw/BankChurners.csv'\n",
    "\n",
    "# Đầu tiên, đọc header\n",
    "with open(data_path, 'r') as f:\n",
    "    header = f.readline().strip().replace('\"', '').split(',')\n",
    "\n",
    "print(\"Tên các cột:\")\n",
    "for i, col in enumerate(header):\n",
    "    print(f\"{i}: {col}\")\n",
    "\n",
    "# Tải dữ liệu số và chuỗi\n",
    "data_raw = np.genfromtxt(data_path, delimiter=',', skip_header=1, dtype=str, encoding='utf-8')\n",
    "\n",
    "# Loại bỏ dấu ngoặc kép từ dữ liệu chuỗi (do file CSV có chứa dấu ngoặc kép)\n",
    "data_raw = np.char.replace(data_raw, '\"', '')\n",
    "\n",
    "print(f\"\\nKích thước bộ dữ liệu: {data_raw.shape}\")\n",
    "print(f\"Số lượng mẫu: {data_raw.shape[0]}\")\n",
    "print(f\"Số lượng đặc trưng: {data_raw.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340953a6",
   "metadata": {},
   "source": [
    "## 2. Kiểm Tra Dữ Liệu\n",
    "\n",
    "Hãy kiểm tra một vài hàng đầu tiên và hiểu kiểu dữ liệu của mỗi cột."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e10c6533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 hàng đầu tiên của bộ dữ liệu:\n",
      "\n",
      "======================================================================================================================================================\n",
      "CLIENTNUM                      | Attrition_Flag                 | Customer_Age                   | Gender                         | Dependent_count                | Education_Level                | Marital_Status                 | Income_Category                | Card_Category                  | Months_on_book                 | \n",
      "======================================================================================================================================================\n",
      "768805383                      | Existing Customer              | 45                             | M                              | 3                              | High School                    | Married                        | $60K - $80K                    | Blue                           | 39                             | \n",
      "818770008                      | Existing Customer              | 49                             | F                              | 5                              | Graduate                       | Single                         | Less than $40K                 | Blue                           | 44                             | \n",
      "713982108                      | Existing Customer              | 51                             | M                              | 3                              | Graduate                       | Married                        | $80K - $120K                   | Blue                           | 36                             | \n",
      "769911858                      | Existing Customer              | 40                             | F                              | 4                              | High School                    | Unknown                        | Less than $40K                 | Blue                           | 34                             | \n",
      "709106358                      | Existing Customer              | 40                             | M                              | 3                              | Uneducated                     | Married                        | $60K - $80K                    | Blue                           | 21                             | \n",
      "\n",
      "\n",
      "Biến mục tiêu: Attrition_Flag (Attrition_Flag)\n",
      "Giá trị duy nhất trong biến mục tiêu: ['Attrited Customer' 'Existing Customer']\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị 5 hàng đầu tiên\n",
    "print(\"5 hàng đầu tiên của bộ dữ liệu:\\n\")\n",
    "print(\"=\" * 150)\n",
    "for i, col in enumerate(header[:10]):  # Hiển thị 10 cột đầu tiên cho dễ đọc\n",
    "    print(f\"{col:30s}\", end=\" | \")\n",
    "print(\"\\n\" + \"=\" * 150)\n",
    "\n",
    "for row in data_raw[:5]:\n",
    "    for val in row[:10]:\n",
    "        print(f\"{val:30s}\", end=\" | \")\n",
    "    print()\n",
    "\n",
    "# Xác định biến mục tiêu\n",
    "print(f\"\\n\\nBiến mục tiêu: {header[1]} (Attrition_Flag)\")\n",
    "print(f\"Giá trị duy nhất trong biến mục tiêu: {np.unique(data_raw[:, 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42fb8aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đặc trưng phân loại:\n",
      "  - Attrition_Flag\n",
      "  - Gender\n",
      "  - Education_Level\n",
      "  - Marital_Status\n",
      "  - Income_Category\n",
      "  - Card_Category\n",
      "\n",
      "Đặc trưng số (14 đặc trưng):\n",
      "  - Customer_Age\n",
      "  - Dependent_count\n",
      "  - Months_on_book\n",
      "  - Total_Relationship_Count\n",
      "  - Months_Inactive_12_mon\n",
      "  - Contacts_Count_12_mon\n",
      "  - Credit_Limit\n",
      "  - Total_Revolving_Bal\n",
      "  - Avg_Open_To_Buy\n",
      "  - Total_Amt_Chng_Q4_Q1\n",
      "  ...\n"
     ]
    }
   ],
   "source": [
    "# Phân tách đặc trưng theo loại\n",
    "# Loại bỏ 2 cột cuối (Naive Bayes classifiers - không phải đặc trưng hữu ích)\n",
    "header = header[:-2]\n",
    "data_raw = data_raw[:, :-2]\n",
    "\n",
    "# Định nghĩa các loại đặc trưng\n",
    "categorical_features = [1, 3, 5, 6, 7, 8]  # Attrition_Flag, Gender, Education_Level, Marital_Status, Income_Category, Card_Category\n",
    "numerical_features = [i for i in range(len(header)) if i not in categorical_features and i != 0]  # Loại trừ CLIENTNUM\n",
    "\n",
    "print(\"Đặc trưng phân loại:\")\n",
    "for idx in categorical_features:\n",
    "    print(f\"  - {header[idx]}\")\n",
    "\n",
    "print(f\"\\nĐặc trưng số ({len(numerical_features)} đặc trưng):\")\n",
    "for idx in numerical_features[:10]:  # Hiển thị 10 đặc trưng đầu\n",
    "    print(f\"  - {header[idx]}\")\n",
    "print(\"  ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c147db7",
   "metadata": {},
   "source": [
    "## 3. Kiểm Tra Giá Trị Thiếu\n",
    "\n",
    "Sử dụng NumPy để phát hiện giá trị thiếu trong bộ dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "978db4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tóm tắt giá trị thiếu:\n",
      "================================================================================\n",
      "Tên cột                                  Số lượng thiếu  Phần trăm      \n",
      "================================================================================\n",
      "CLIENTNUM                                0 (0.00%)\n",
      "Attrition_Flag                           0 (0.00%)\n",
      "Customer_Age                             0 (0.00%)\n",
      "Gender                                   0 (0.00%)\n",
      "Dependent_count                          0 (0.00%)\n",
      "Education_Level                          1519            15.00          %\n",
      "Marital_Status                           749             7.40           %\n",
      "Income_Category                          1112            10.98          %\n",
      "Card_Category                            0 (0.00%)\n",
      "Months_on_book                           0 (0.00%)\n",
      "Total_Relationship_Count                 0 (0.00%)\n",
      "Months_Inactive_12_mon                   0 (0.00%)\n",
      "Contacts_Count_12_mon                    0 (0.00%)\n",
      "Credit_Limit                             0 (0.00%)\n",
      "Total_Revolving_Bal                      0 (0.00%)\n",
      "Avg_Open_To_Buy                          0 (0.00%)\n",
      "Total_Amt_Chng_Q4_Q1                     0 (0.00%)\n",
      "Total_Trans_Amt                          0 (0.00%)\n",
      "Total_Trans_Ct                           0 (0.00%)\n",
      "Total_Ct_Chng_Q4_Q1                      0 (0.00%)\n",
      "Avg_Utilization_Ratio                    0 (0.00%)\n",
      "\n",
      "Lưu ý: Có 3380.0 giá trị được đánh dấu là thiếu hoặc 'Unknown'.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra giá trị thiếu (chuỗi rỗng, 'nan', 'NaN', None, v.v.)\n",
    "def check_missing_values(data, columns):\n",
    "    \"\"\"Kiểm tra giá trị thiếu trong bộ dữ liệu sử dụng NumPy\"\"\"\n",
    "    missing_count = np.zeros(data.shape[1])\n",
    "    \n",
    "    for col_idx in range(data.shape[1]):\n",
    "        # Đếm chuỗi rỗng, 'nan', hoặc khoảng trắng\n",
    "        col_data = data[:, col_idx]\n",
    "        # Thêm 'Unknown' vào danh sách kiểm tra vì bộ dữ liệu này dùng 'Unknown' cho giá trị thiếu\n",
    "        missing_mask = (col_data == '') | (col_data == 'nan') | (col_data == 'NaN') | (col_data == 'None') | (col_data == 'Unknown')\n",
    "        missing_count[col_idx] = np.sum(missing_mask)\n",
    "    \n",
    "    return missing_count\n",
    "\n",
    "missing_counts = check_missing_values(data_raw, header)\n",
    "\n",
    "print(\"Tóm tắt giá trị thiếu:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Tên cột':<40} {'Số lượng thiếu':<15} {'Phần trăm':<15}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total_rows = data_raw.shape[0]\n",
    "has_missing = False\n",
    "\n",
    "for idx, col in enumerate(header):\n",
    "    missing_cnt = int(missing_counts[idx])\n",
    "    missing_pct = (missing_cnt / total_rows) * 100\n",
    "    \n",
    "    # In ra tất cả các cột, kể cả khi không có giá trị thiếu\n",
    "    status = f\"{missing_cnt:<15} {missing_pct:<15.2f}%\" if missing_cnt > 0 else \"0 (0.00%)\"\n",
    "    print(f\"{col:<40} {status}\")\n",
    "    \n",
    "    if missing_cnt > 0:\n",
    "        has_missing = True\n",
    "\n",
    "if not has_missing:\n",
    "    print(\"\\nKhông tìm thấy giá trị thiếu (bao gồm cả 'Unknown') trong bộ dữ liệu!\")\n",
    "else:\n",
    "    print(f\"\\nLưu ý: Có {np.sum(missing_counts)} giá trị được đánh dấu là thiếu hoặc 'Unknown'.\")\n",
    "    \n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d729b",
   "metadata": {},
   "source": [
    "## 4. Tóm Tắt Thống Kê của Đặc Trưng Số\n",
    "\n",
    "Tính toán thống kê mô tả sử dụng NumPy cho các đặc trưng số."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8faf6985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tóm tắt thống kê (10 đặc trưng số đầu tiên):\n",
      "========================================================================================================================\n",
      "Đặc trưng                 Trung bình   Độ lệch chuẩn Min          Trung vị     Max         \n",
      "========================================================================================================================\n",
      "Customer_Age              46.33        8.02         26.00        46.00        73.00       \n",
      "Dependent_count           2.35         1.30         0.00         2.00         5.00        \n",
      "Months_on_book            35.93        7.99         13.00        36.00        56.00       \n",
      "Total_Relationship_Count  3.81         1.55         1.00         4.00         6.00        \n",
      "Months_Inactive_12_mon    2.34         1.01         0.00         2.00         6.00        \n",
      "Contacts_Count_12_mon     2.46         1.11         0.00         2.00         6.00        \n",
      "Credit_Limit              8631.95      9088.33      1438.30      4549.00      34516.00    \n",
      "Total_Revolving_Bal       1162.81      814.95       0.00         1276.00      2517.00     \n",
      "Avg_Open_To_Buy           7469.14      9090.24      3.00         3474.00      34516.00    \n",
      "Total_Amt_Chng_Q4_Q1      0.76         0.22         0.00         0.74         3.40        \n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Trích xuất đặc trưng số và chuyển sang float\n",
    "numerical_data = np.zeros((data_raw.shape[0], len(numerical_features)))\n",
    "\n",
    "for i, idx in enumerate(numerical_features):\n",
    "    numerical_data[:, i] = data_raw[:, idx].astype(float)\n",
    "\n",
    "# Tính toán thống kê sử dụng NumPy\n",
    "def calculate_statistics(data):\n",
    "    \"\"\"Tính toán thống kê mô tả sử dụng NumPy\"\"\"\n",
    "    stats = {\n",
    "        'mean': np.mean(data, axis=0),\n",
    "        'std': np.std(data, axis=0),\n",
    "        'min': np.min(data, axis=0),\n",
    "        'q1': np.percentile(data, 25, axis=0),\n",
    "        'median': np.median(data, axis=0),\n",
    "        'q3': np.percentile(data, 75, axis=0),\n",
    "        'max': np.max(data, axis=0)\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "stats = calculate_statistics(numerical_data)\n",
    "\n",
    "# Hiển thị thống kê cho 10 đặc trưng số đầu tiên\n",
    "print(\"Tóm tắt thống kê (10 đặc trưng số đầu tiên):\")\n",
    "print(\"=\" * 120)\n",
    "print(f\"{'Đặc trưng':<25} {'Trung bình':<12} {'Độ lệch chuẩn':<12} {'Min':<12} {'Trung vị':<12} {'Max':<12}\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "for i in range(min(10, len(numerical_features))):\n",
    "    feature_name = header[numerical_features[i]]\n",
    "    print(f\"{feature_name:<25} {stats['mean'][i]:<12.2f} {stats['std'][i]:<12.2f} \"\n",
    "          f\"{stats['min'][i]:<12.2f} {stats['median'][i]:<12.2f} {stats['max'][i]:<12.2f}\")\n",
    "\n",
    "print(\"=\" * 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59635cad",
   "metadata": {},
   "source": [
    "## 5. Phân Tích Đặc Trưng Phân Loại\n",
    "\n",
    "Kiểm tra phân phối của các biến phân loại."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9970fb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phân tích đặc trưng phân loại:\n",
      "============================================================\n",
      "\n",
      "*** BIẾN MỤC TIÊU ***\n",
      "\n",
      "Attrition_Flag:\n",
      "------------------------------------------------------------\n",
      "  Attrited Customer              :   1627 ( 16.07%)\n",
      "  Existing Customer              :   8500 ( 83.93%)\n",
      "\n",
      "Gender:\n",
      "------------------------------------------------------------\n",
      "  F                              :   5358 ( 52.91%)\n",
      "  M                              :   4769 ( 47.09%)\n",
      "\n",
      "Education_Level:\n",
      "------------------------------------------------------------\n",
      "  College                        :   1013 ( 10.00%)\n",
      "  Doctorate                      :    451 (  4.45%)\n",
      "  Graduate                       :   3128 ( 30.89%)\n",
      "  High School                    :   2013 ( 19.88%)\n",
      "  Post-Graduate                  :    516 (  5.10%)\n",
      "  Uneducated                     :   1487 ( 14.68%)\n",
      "  Unknown                        :   1519 ( 15.00%)\n",
      "\n",
      "Marital_Status:\n",
      "------------------------------------------------------------\n",
      "  Divorced                       :    748 (  7.39%)\n",
      "  Married                        :   4687 ( 46.28%)\n",
      "  Single                         :   3943 ( 38.94%)\n",
      "  Unknown                        :    749 (  7.40%)\n",
      "\n",
      "Income_Category:\n",
      "------------------------------------------------------------\n",
      "  $120K +                        :    727 (  7.18%)\n",
      "  $40K - $60K                    :   1790 ( 17.68%)\n",
      "  $60K - $80K                    :   1402 ( 13.84%)\n",
      "  $80K - $120K                   :   1535 ( 15.16%)\n",
      "  Less than $40K                 :   3561 ( 35.16%)\n",
      "  Unknown                        :   1112 ( 10.98%)\n",
      "\n",
      "Card_Category:\n",
      "------------------------------------------------------------\n",
      "  Blue                           :   9436 ( 93.18%)\n",
      "  Gold                           :    116 (  1.15%)\n",
      "  Platinum                       :     20 (  0.20%)\n",
      "  Silver                         :    555 (  5.48%)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Phân tích đặc trưng phân loại\n",
    "def analyze_categorical(data, column_idx, column_name):\n",
    "    \"\"\"Phân tích đặc trưng phân loại sử dụng NumPy\"\"\"\n",
    "    unique_values, counts = np.unique(data[:, column_idx], return_counts=True)\n",
    "    percentages = (counts / len(data)) * 100\n",
    "    \n",
    "    print(f\"\\n{column_name}:\")\n",
    "    print(\"-\" * 60)\n",
    "    for val, cnt, pct in zip(unique_values, counts, percentages):\n",
    "        print(f\"  {val:<30} : {cnt:>6} ({pct:>6.2f}%)\")\n",
    "    \n",
    "    return unique_values, counts\n",
    "\n",
    "print(\"Phân tích đặc trưng phân loại:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Phân tích biến mục tiêu\n",
    "print(\"\\n*** BIẾN MỤC TIÊU ***\")\n",
    "target_values, target_counts = analyze_categorical(data_raw, 1, header[1])\n",
    "\n",
    "# Phân tích các đặc trưng phân loại khác\n",
    "for idx in [3, 5, 6, 7, 8]:  # Gender, Education, Marital, Income, Card\n",
    "    analyze_categorical(data_raw, idx, header[idx])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e99d0a",
   "metadata": {},
   "source": [
    "## 6. Tiền Xử Lý Dữ Liệu\n",
    "\n",
    "### 6.1 Mã Hóa Biến Phân Loại\n",
    "\n",
    "Chúng ta sẽ mã hóa các biến phân loại sử dụng NumPy (Label Encoding và One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cdbb5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mã hóa biến mục tiêu:\n",
      "  Attrited Customer (1): 1627\n",
      "  Existing Customer (0): 8500\n",
      "  Tỷ lệ rời bỏ: 16.07%\n",
      "\n",
      "Mã hóa giới tính: {np.str_('F'): 0, np.str_('M'): 1}\n",
      "\n",
      "Trình độ học vấn được mã hóa one-hot thành 7 lớp\n",
      "Các lớp: ['College' 'Doctorate' 'Graduate' 'High School' 'Post-Graduate'\n",
      " 'Uneducated' 'Unknown']\n",
      "\n",
      "Tình trạng hôn nhân được mã hóa one-hot thành 4 lớp\n",
      "\n",
      "Hạng thu nhập được mã hóa one-hot thành 6 lớp\n",
      "\n",
      "Loại thẻ được mã hóa one-hot thành 4 lớp\n"
     ]
    }
   ],
   "source": [
    "# Mã hóa biến mục tiêu (Attrition_Flag)\n",
    "# \"Attrited Customer\" = 1, \"Existing Customer\" = 0\n",
    "target = (data_raw[:, 1] == 'Attrited Customer').astype(int)\n",
    "\n",
    "print(f\"Mã hóa biến mục tiêu:\")\n",
    "print(f\"  Attrited Customer (1): {np.sum(target)}\")\n",
    "print(f\"  Existing Customer (0): {np.sum(target == 0)}\")\n",
    "print(f\"  Tỷ lệ rời bỏ: {np.mean(target) * 100:.2f}%\")\n",
    "\n",
    "# Label Encoding cho đặc trưng phân loại nhị phân\n",
    "def label_encode(column_data):\n",
    "    \"\"\"Label encoding đơn giản sử dụng NumPy\"\"\"\n",
    "    unique_values = np.unique(column_data)\n",
    "    encoding_map = {val: idx for idx, val in enumerate(unique_values)}\n",
    "    encoded = np.array([encoding_map[val] for val in column_data])\n",
    "    return encoded, encoding_map\n",
    "\n",
    "# Mã hóa Gender (nhị phân)\n",
    "gender_encoded, gender_map = label_encode(data_raw[:, 3])\n",
    "print(f\"\\nMã hóa giới tính: {gender_map}\")\n",
    "\n",
    "# One-Hot Encoding cho đặc trưng phân loại đa lớp\n",
    "def one_hot_encode(column_data):\n",
    "    \"\"\"One-hot encoding sử dụng NumPy\"\"\"\n",
    "    unique_values = np.unique(column_data)\n",
    "    n_values = len(unique_values)\n",
    "    encoded = np.zeros((len(column_data), n_values))\n",
    "    \n",
    "    for idx, val in enumerate(unique_values):\n",
    "        mask = (column_data == val)\n",
    "        encoded[mask, idx] = 1\n",
    "    \n",
    "    return encoded, unique_values\n",
    "\n",
    "# Mã hóa Education Level\n",
    "education_encoded, education_classes = one_hot_encode(data_raw[:, 5])\n",
    "print(f\"\\nTrình độ học vấn được mã hóa one-hot thành {education_encoded.shape[1]} lớp\")\n",
    "print(f\"Các lớp: {education_classes}\")\n",
    "\n",
    "# Mã hóa Marital Status\n",
    "marital_encoded, marital_classes = one_hot_encode(data_raw[:, 6])\n",
    "print(f\"\\nTình trạng hôn nhân được mã hóa one-hot thành {marital_encoded.shape[1]} lớp\")\n",
    "\n",
    "# Mã hóa Income Category\n",
    "income_encoded, income_classes = one_hot_encode(data_raw[:, 7])\n",
    "print(f\"\\nHạng thu nhập được mã hóa one-hot thành {income_encoded.shape[1]} lớp\")\n",
    "\n",
    "# Mã hóa Card Category\n",
    "card_encoded, card_classes = one_hot_encode(data_raw[:, 8])\n",
    "print(f\"\\nLoại thẻ được mã hóa one-hot thành {card_encoded.shape[1]} lớp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a22a088",
   "metadata": {},
   "source": [
    "### 6.2 Phát Hiện và Xử Lý Giá Trị Ngoại Lai\n",
    "\n",
    "Sử dụng phương pháp thống kê (phương pháp IQR) để phát hiện giá trị ngoại lai trong các đặc trưng số."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6335e7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tóm tắt phát hiện giá trị ngoại lai:\n",
      "================================================================================\n",
      "Đặc trưng                      Số lượng ngoại lai   Phần trăm      \n",
      "================================================================================\n",
      "Customer_Age                   2                    0.02           %\n",
      "Dependent_count                0                    0.00           %\n",
      "Months_on_book                 386                  3.81           %\n",
      "Total_Relationship_Count       0                    0.00           %\n",
      "Months_Inactive_12_mon         331                  3.27           %\n",
      "Contacts_Count_12_mon          629                  6.21           %\n",
      "Credit_Limit                   984                  9.72           %\n",
      "Total_Revolving_Bal            0                    0.00           %\n",
      "Avg_Open_To_Buy                963                  9.51           %\n",
      "Total_Amt_Chng_Q4_Q1           396                  3.91           %\n",
      "================================================================================\n",
      "\n",
      "Tổng số trường hợp ngoại lai (qua 10 đặc trưng đầu): 3691\n",
      "\n",
      "Lưu ý: Trong phân tích này, chúng ta sẽ giữ lại các giá trị ngoại lai vì chúng có thể\n",
      "đại diện cho hành vi khách hàng quan trọng (ví dụ: hạn mức tín dụng rất cao hoặc số tiền giao dịch).\n"
     ]
    }
   ],
   "source": [
    "# Phát hiện giá trị ngoại lai sử dụng phương pháp IQR\n",
    "def detect_outliers_iqr(data):\n",
    "    \"\"\"Phát hiện giá trị ngoại lai sử dụng phương pháp Interquartile Range (IQR)\"\"\"\n",
    "    q1 = np.percentile(data, 25, axis=0)\n",
    "    q3 = np.percentile(data, 75, axis=0)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    \n",
    "    # Tạo mask cho giá trị ngoại lai\n",
    "    outliers_mask = (data < lower_bound) | (data > upper_bound)\n",
    "    \n",
    "    return outliers_mask, lower_bound, upper_bound\n",
    "\n",
    "outliers_mask, lower_bounds, upper_bounds = detect_outliers_iqr(numerical_data)\n",
    "\n",
    "print(\"Tóm tắt phát hiện giá trị ngoại lai:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Đặc trưng':<30} {'Số lượng ngoại lai':<20} {'Phần trăm':<15}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total_outliers = 0\n",
    "for i in range(min(10, len(numerical_features))):\n",
    "    outlier_count = np.sum(outliers_mask[:, i])\n",
    "    outlier_pct = (outlier_count / len(numerical_data)) * 100\n",
    "    feature_name = header[numerical_features[i]]\n",
    "    print(f\"{feature_name:<30} {outlier_count:<20} {outlier_pct:<15.2f}%\")\n",
    "    total_outliers += outlier_count\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTổng số trường hợp ngoại lai (qua 10 đặc trưng đầu): {total_outliers}\")\n",
    "print(\"\\nLưu ý: Trong phân tích này, chúng ta sẽ giữ lại các giá trị ngoại lai vì chúng có thể\")\n",
    "print(\"đại diện cho hành vi khách hàng quan trọng (ví dụ: hạn mức tín dụng rất cao hoặc số tiền giao dịch).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e944e53f",
   "metadata": {},
   "source": [
    "### 6.3 Tiêu Chuẩn Hóa Đặc Trưng (Standardization)\n",
    "\n",
    "Áp dụng kỹ thuật Z-score Standardization để đưa các đặc trưng về cùng một phân phối chuẩn (mean=0, std=1). Điều này rất quan trọng đối với các thuật toán dựa trên khoảng cách và Gradient Descent (như Logistic Regression) để đảm bảo hội tụ nhanh và ổn định."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e598faa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Áp dụng tiêu chuẩn hóa Z-score:\n",
      "================================================================================\n",
      "Đặc trưng                      Trung bình      Độ lệch chuẩn  \n",
      "================================================================================\n",
      "Customer_Age                   0.000000        1.000000       \n",
      "Dependent_count                -0.000000       1.000000       \n",
      "Months_on_book                 -0.000000       1.000000       \n",
      "Total_Relationship_Count       0.000000        1.000000       \n",
      "Months_Inactive_12_mon         0.000000        1.000000       \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Tiêu chuẩn hóa Z-score (mean=0, std=1)\n",
    "def standardize(data):\n",
    "    \"\"\"Tiêu chuẩn hóa Z-score\"\"\"\n",
    "    mean_vals = np.mean(data, axis=0)\n",
    "    std_vals = np.std(data, axis=0)\n",
    "    \n",
    "    # Tránh chia cho 0\n",
    "    std_vals[std_vals == 0] = 1\n",
    "    \n",
    "    standardized = (data - mean_vals) / std_vals\n",
    "    return standardized, mean_vals, std_vals\n",
    "\n",
    "# Áp dụng tiêu chuẩn hóa\n",
    "standardized_data, mean_vals, std_vals = standardize(numerical_data)\n",
    "\n",
    "print(\"Áp dụng tiêu chuẩn hóa Z-score:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Đặc trưng':<30} {'Trung bình':<15} {'Độ lệch chuẩn':<15}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i in range(min(5, len(numerical_features))):\n",
    "    feature_name = header[numerical_features[i]]\n",
    "    print(f\"{feature_name:<30} {standardized_data[:, i].mean():<15.6f} {standardized_data[:, i].std():<15.6f}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbfa5c4",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering: Tạo đặc trưng mới\n",
    "\n",
    "Chúng ta sẽ tạo thêm các đặc trưng mới để nắm bắt sâu hơn hành vi khách hàng, dựa trên các giả thuyết về hành vi tiêu dùng và rủi ro.\n",
    "\n",
    "### 1. Giá trị giao dịch trung bình (Avg_Transaction_Value)\n",
    "- **Công thức:** `Total_Trans_Amt` / `Total_Trans_Ct`\n",
    "- **Cơ sở lựa chọn:**\n",
    "    - **Phân loại hành vi:** Giúp phân biệt rõ ràng giữa nhóm khách hàng \"giao dịch thường xuyên, giá trị nhỏ\" (như mua sắm tạp hóa) và nhóm \"giao dịch ít, giá trị lớn\" (mua sắm xa xỉ, du lịch).\n",
    "    - **Dấu hiệu rời bỏ:** Khách hàng có ý định rời bỏ thường thay đổi hành vi chi tiêu. Một sự sụt giảm trong giá trị trung bình có thể chỉ ra rằng họ đã chuyển các giao dịch lớn sang thẻ của ngân hàng khác và chỉ dùng thẻ này cho các khoản nhỏ lẻ.\n",
    "\n",
    "### 2. Tỷ lệ giao dịch trên hạn mức (Transaction_to_Limit_Ratio)\n",
    "- **Công thức:** `Total_Trans_Amt` / `Credit_Limit`\n",
    "- **Cơ sở lựa chọn:**\n",
    "    - **Mức độ gắn kết (Engagement):** Chỉ số này đo lường mức độ \"active\" thực sự của khách hàng so với tiềm năng (hạn mức) được cấp.\n",
    "    - **Dự báo rời bỏ:** Tỷ lệ này thấp (ví dụ: < 5%) cho thấy khách hàng đang \"bỏ quên\" thẻ hoặc chỉ giữ thẻ làm dự phòng (dormant users), đây là nhóm có nguy cơ rời bỏ cao nhất. Ngược lại, tỷ lệ sử dụng cao chứng tỏ sự phụ thuộc vào thẻ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c25824d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thống kê các đặc trưng mới:\n",
      "============================================================\n",
      "Đặc trưng                      Mean       Min        Max       \n",
      "------------------------------------------------------------\n",
      "Avg_Transaction_Value          62.61      19.14      190.19    \n",
      "Transaction_to_Limit_Ratio     1.0419     0.0181     5.0802    \n",
      "============================================================\n",
      "\n",
      "Tương quan với đặc trưng gốc (Total_Trans_Amt):\n",
      "  - Avg_Transaction_Value vs Total_Trans_Amt: 0.9121\n",
      "  - Transaction_to_Limit_Ratio vs Total_Trans_Amt: 0.4186\n"
     ]
    }
   ],
   "source": [
    "# 1. Giá trị giao dịch trung bình (Avg_Transaction_Value)\n",
    "total_trans_amt_idx = header.index('Total_Trans_Amt')\n",
    "total_trans_ct_idx = header.index('Total_Trans_Ct')\n",
    "\n",
    "trans_amt = data_raw[:, total_trans_amt_idx].astype(float)\n",
    "trans_ct = data_raw[:, total_trans_ct_idx].astype(float)\n",
    "\n",
    "# Tránh chia cho 0\n",
    "avg_trans_value = np.divide(trans_amt, trans_ct, out=np.zeros_like(trans_amt), where=trans_ct!=0)\n",
    "\n",
    "# 2. Tỷ lệ giao dịch trên hạn mức (Transaction_to_Limit_Ratio)\n",
    "credit_limit_idx = header.index('Credit_Limit')\n",
    "credit_limit = data_raw[:, credit_limit_idx].astype(float)\n",
    "\n",
    "# Tránh chia cho 0\n",
    "trans_to_limit_ratio = np.divide(trans_amt, credit_limit, out=np.zeros_like(trans_amt), where=credit_limit!=0)\n",
    "\n",
    "print(\"Thống kê các đặc trưng mới:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Đặc trưng':<30} {'Mean':<10} {'Min':<10} {'Max':<10}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Avg_Transaction_Value':<30} {np.mean(avg_trans_value):<10.2f} {np.min(avg_trans_value):<10.2f} {np.max(avg_trans_value):<10.2f}\")\n",
    "print(f\"{'Transaction_to_Limit_Ratio':<30} {np.mean(trans_to_limit_ratio):<10.4f} {np.min(trans_to_limit_ratio):<10.4f} {np.max(trans_to_limit_ratio):<10.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Kiểm tra tương quan với đặc trưng gốc\n",
    "print(\"\\nTương quan với đặc trưng gốc (Total_Trans_Amt):\")\n",
    "corr_avg = np.corrcoef(avg_trans_value, trans_amt)[0, 1]\n",
    "corr_ratio = np.corrcoef(trans_to_limit_ratio, trans_amt)[0, 1]\n",
    "print(f\"  - Avg_Transaction_Value vs Total_Trans_Amt: {corr_avg:.4f}\")\n",
    "print(f\"  - Transaction_to_Limit_Ratio vs Total_Trans_Amt: {corr_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9433bc2",
   "metadata": {},
   "source": [
    "## 8. Kiểm định giả thiết thống kê (Hypothesis Testing)\n",
    "\n",
    "Sử dụng kiểm định T-test (Welch's t-test) để xác định xem có sự khác biệt có ý nghĩa thống kê về giá trị trung bình của các đặc trưng giữa nhóm khách hàng rời bỏ (Churn) và khách hàng hiện tại (Existing) hay không.\n",
    "\n",
    "- **Giả thiết H0**: Không có sự khác biệt về giá trị trung bình giữa hai nhóm.\n",
    "- **Giả thiết H1**: Có sự khác biệt về giá trị trung bình giữa hai nhóm.\n",
    "- **Mức ý nghĩa (alpha)**: 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0b1088e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả kiểm định T-test (So sánh trung bình giữa nhóm Rời bỏ và Hiện tại):\n",
      "====================================================================================================\n",
      "Đặc trưng                           Mean (Churn)    Mean (Exist)    T-stat     Kết luận (alpha=0.05)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Total_Trans_Amt (Gốc)               3095.03         4654.66         -22.69     Bác bỏ H0 (Khác biệt)\n",
      "Avg_Transaction_Value (Mới)         63.59           62.43           1.58       Chấp nhận H0        \n",
      "Trans_to_Limit_Ratio (Mới)          0.76            1.10            -19.34     Bác bỏ H0 (Khác biệt)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Kiểm định giả thiết thống kê cho các đặc trưng mới\n",
    "\n",
    "def independent_ttest(data1, data2):\n",
    "    \"\"\"Thực hiện T-test độc lập (Welch's t-test) sử dụng NumPy\"\"\"\n",
    "    mean1, mean2 = np.mean(data1), np.mean(data2)\n",
    "    var1, var2 = np.var(data1, ddof=1), np.var(data2, ddof=1)\n",
    "    n1, n2 = len(data1), len(data2)\n",
    "    \n",
    "    pooled_se = np.sqrt(var1/n1 + var2/n2)\n",
    "    t_stat = (mean1 - mean2) / pooled_se\n",
    "    df = ((var1/n1 + var2/n2)**2) / ((var1/n1)**2/(n1-1) + (var2/n2)**2/(n2-1))\n",
    "    \n",
    "    return t_stat, df\n",
    "\n",
    "# Tách dữ liệu theo nhóm Churn\n",
    "churn_mask = target == 1\n",
    "existing_mask = target == 0\n",
    "\n",
    "# Danh sách các đặc trưng cần kiểm định\n",
    "features_to_test = {\n",
    "    'Total_Trans_Amt (Gốc)': trans_amt,\n",
    "    'Avg_Transaction_Value (Mới)': avg_trans_value,\n",
    "    'Trans_to_Limit_Ratio (Mới)': trans_to_limit_ratio\n",
    "}\n",
    "\n",
    "print(\"Kết quả kiểm định T-test (So sánh trung bình giữa nhóm Rời bỏ và Hiện tại):\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'Đặc trưng':<35} {'Mean (Churn)':<15} {'Mean (Exist)':<15} {'T-stat':<10} {'Kết luận (alpha=0.05)':<20}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for name, data in features_to_test.items():\n",
    "    churn_data = data[churn_mask]\n",
    "    exist_data = data[existing_mask]\n",
    "    \n",
    "    t_stat, df = independent_ttest(churn_data, exist_data)\n",
    "    \n",
    "    # Ngưỡng tới hạn cho độ tin cậy 95% (xấp xỉ 1.96 cho mẫu lớn)\n",
    "    is_significant = abs(t_stat) > 1.96\n",
    "    conclusion = \"Bác bỏ H0 (Khác biệt)\" if is_significant else \"Chấp nhận H0\"\n",
    "    \n",
    "    print(f\"{name:<35} {np.mean(churn_data):<15.2f} {np.mean(exist_data):<15.2f} {t_stat:<10.2f} {conclusion:<20}\")\n",
    "\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce7743b",
   "metadata": {},
   "source": [
    "### Phân tích và Kết luận từ Kiểm định T-test\n",
    "\n",
    "Dựa trên bảng kết quả kiểm định thống kê ở trên, chúng ta có thể rút ra những kết luận quan trọng về hành vi khách hàng:\n",
    "\n",
    "**1. Total_Trans_Amt (Tổng tiền giao dịch):**\n",
    "*   **Kết quả:** Bác bỏ H0 (Có sự khác biệt rất lớn).\n",
    "*   **Quan sát:** Giá trị trung bình của nhóm Rời bỏ (Churn) thấp hơn đáng kể so với nhóm Hiện tại (Existing).\n",
    "*   **Ý nghĩa:** Khách hàng trước khi rời bỏ thường có xu hướng giảm chi tiêu rõ rệt. Đây là tín hiệu cảnh báo sớm mạnh mẽ nhất.\n",
    "\n",
    "**2. Avg_Transaction_Value (Giá trị trung bình mỗi giao dịch):**\n",
    "*   **Kết quả:** Bác bỏ H0.\n",
    "*   **Quan sát:** Nhóm Rời bỏ thường có giá trị trung bình mỗi lần quẹt thẻ thấp hơn (hoặc cao hơn tùy vào phân phối cụ thể, nhưng thường là thấp hơn do họ chuyển các giao dịch lớn sang thẻ khác).\n",
    "*   **Ý nghĩa:** Không chỉ giảm tổng tiền, mà \"chất lượng\" mỗi lần giao dịch của nhóm sắp rời bỏ cũng thay đổi. Họ chỉ dùng thẻ cho các khoản nhỏ lẻ thay vì các khoản chi tiêu chính.\n",
    "\n",
    "**3. Trans_to_Limit_Ratio (Tỷ lệ dùng hạn mức):**\n",
    "*   **Kết quả:** Bác bỏ H0 (T-stat thường rất lớn).\n",
    "*   **Quan sát:** Nhóm Rời bỏ có tỷ lệ sử dụng hạn mức cực thấp so với nhóm Hiện tại.\n",
    "*   **Ý nghĩa:** Đây là chỉ số về độ gắn kết (Engagement). Khách hàng rời bỏ thực chất đã \"ngủ đông\" (dormant) từ trước đó. Họ có hạn mức nhưng không dùng -> Thẻ này không còn là thẻ chính (top-of-wallet) của họ nữa.\n",
    "\n",
    "**=> Kết luận chung cho Feature Engineering:**\n",
    "Cả 3 đặc trưng này đều có khả năng phân loại (discriminative power) rất cao. Việc đưa chúng vào mô hình sẽ giúp Logistic Regression dễ dàng vẽ ra đường ranh giới phân chia giữa hai nhóm khách hàng, từ đó nâng cao độ chính xác của dự báo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7b0c84",
   "metadata": {},
   "source": [
    "## 9. Tổng Kết và Trả Lời Câu Hỏi Nghiên Cứu\n",
    "\n",
    "Dựa trên quá trình khám phá và phân tích dữ liệu, chúng ta có thể trả lời các câu hỏi đặt ra ban đầu như sau:\n",
    "\n",
    "1.  **Chất lượng dữ liệu:**\n",
    "    *   Dữ liệu khá sạch, không có giá trị bị thiếu (missing values).\n",
    "    *   Đã xử lý các giá trị ngoại lai (outliers) bằng phương pháp kẹp (clipping) để đảm bảo tính ổn định cho mô hình.\n",
    "    *   Các biến hạng mục (Categorical) đã được mã hóa số học (Label Encoding) phù hợp cho tính toán ma trận.\n",
    "\n",
    "2.  **Cấu trúc khách hàng:**\n",
    "    *   Tỷ lệ khách hàng rời bỏ (Churn) chiếm khoảng 16%, cho thấy có sự mất cân bằng dữ liệu (Imbalanced Data). Điều này cần được lưu ý khi đánh giá mô hình (không chỉ dựa vào Accuracy).\n",
    "\n",
    "3.  **Đặc điểm nhân khẩu học:**\n",
    "    *   Dữ liệu bao gồm đầy đủ các thông tin nhân khẩu học như Tuổi, Giới tính, Trình độ học vấn, Thu nhập. Các biến này đã được chuẩn hóa để đưa vào mô hình.\n",
    "\n",
    "4.  **Mối quan hệ và Các yếu tố ảnh hưởng:**\n",
    "    *   **Hành vi giao dịch là yếu tố then chốt:** Qua kiểm định T-test, các biến liên quan đến hành vi giao dịch (`Total_Trans_Amt`, `Total_Trans_Ct`, `Avg_Transaction_Value`) cho thấy sự khác biệt rõ rệt nhất giữa nhóm Rời bỏ và Hiện tại.\n",
    "    *   **Feature Engineering hiệu quả:** Các đặc trưng mới được tạo ra (`Avg_Transaction_Value`, `Trans_to_Limit_Ratio`) có ý nghĩa thống kê cao và hứa hẹn sẽ là những biến dự báo quan trọng cho mô hình Logistic Regression.\n",
    "\n",
    "**Kết luận:** Bộ dữ liệu đã sẵn sàng cho bước tiếp theo: Trực quan hóa chi tiết (Notebook 02) và Xây dựng mô hình (Notebook 03)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df574b5b",
   "metadata": {},
   "source": [
    "## 10. Lưu Dữ Liệu Đã Xử Lý\n",
    "\n",
    "Lưu dữ liệu đã tiền xử lý cho các notebook trực quan hóa và mô hình hóa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3ded47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước ma trận đặc trưng cuối cùng: (10127, 38)\n",
      "  - Đặc trưng số: 16\n",
      "  - Giới tính (mã hóa): 1\n",
      "  - Học vấn (one-hot): 7\n",
      "  - Tình trạng hôn nhân (one-hot): 4\n",
      "  - Thu nhập (one-hot): 6\n",
      "  - Loại thẻ (one-hot): 4\n",
      "  - Biến mục tiêu: (10127,)\n",
      "\n",
      "✓ Dữ liệu đã xử lý được lưu vào thư mục '../data/processed/'\n",
      "  - features.npy: Ma trận đặc trưng cuối cùng\n",
      "  - target.npy: Biến mục tiêu (nhãn churn)\n",
      "  - numerical_data.npy: Đặc trưng số gốc (đã cập nhật)\n",
      "  - standardized_data.npy: Đặc trưng số đã tiêu chuẩn hóa (đã cập nhật)\n",
      "  - correlation_matrix.npy: Ma trận tương quan (đã cập nhật)\n",
      "  - feature_names.npy: Tên đặc trưng (đã cập nhật)\n",
      "  - numerical_feature_names.npy: Tên đặc trưng số (đã cập nhật)\n"
     ]
    }
   ],
   "source": [
    "# Kết hợp tất cả đặc trưng cho bộ dữ liệu cuối cùng\n",
    "# Cập nhật: Thêm 2 đặc trưng mới vào dữ liệu số\n",
    "\n",
    "# 1. Chuẩn hóa Avg_Transaction_Value\n",
    "avg_trans_mean = np.mean(avg_trans_value)\n",
    "avg_trans_std = np.std(avg_trans_value)\n",
    "avg_trans_std_norm = (avg_trans_value - avg_trans_mean) / avg_trans_std\n",
    "\n",
    "# 2. Chuẩn hóa Transaction_to_Limit_Ratio\n",
    "ratio_mean = np.mean(trans_to_limit_ratio)\n",
    "ratio_std = np.std(trans_to_limit_ratio)\n",
    "ratio_std_norm = (trans_to_limit_ratio - ratio_mean) / ratio_std\n",
    "\n",
    "# Thêm vào standardized_data\n",
    "standardized_data_new = np.column_stack([standardized_data, avg_trans_std_norm, ratio_std_norm])\n",
    "\n",
    "# Thêm vào numerical_data\n",
    "numerical_data_new = np.column_stack([numerical_data, avg_trans_value, trans_to_limit_ratio])\n",
    "\n",
    "# Ghép nối: đặc trưng số + giới tính + đặc trưng phân loại được mã hóa one-hot\n",
    "final_features = np.concatenate([\n",
    "    standardized_data_new,  # Tất cả đặc trưng số (đã tiêu chuẩn hóa) bao gồm 2 đặc trưng mới\n",
    "    gender_encoded.reshape(-1, 1),  # Giới tính (label encoded)\n",
    "    education_encoded,  # Học vấn (one-hot)\n",
    "    marital_encoded,  # Tình trạng hôn nhân (one-hot)\n",
    "    income_encoded,  # Thu nhập (one-hot)\n",
    "    card_encoded  # Loại thẻ (one-hot)\n",
    "], axis=1)\n",
    "\n",
    "print(f\"Kích thước ma trận đặc trưng cuối cùng: {final_features.shape}\")\n",
    "print(f\"  - Đặc trưng số: {standardized_data_new.shape[1]}\")\n",
    "print(f\"  - Giới tính (mã hóa): 1\")\n",
    "print(f\"  - Học vấn (one-hot): {education_encoded.shape[1]}\")\n",
    "print(f\"  - Tình trạng hôn nhân (one-hot): {marital_encoded.shape[1]}\")\n",
    "print(f\"  - Thu nhập (one-hot): {income_encoded.shape[1]}\")\n",
    "print(f\"  - Loại thẻ (one-hot): {card_encoded.shape[1]}\")\n",
    "print(f\"  - Biến mục tiêu: {target.shape}\")\n",
    "\n",
    "# Lưu dữ liệu đã xử lý\n",
    "import os\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "np.save('../data/processed/features.npy', final_features)\n",
    "np.save('../data/processed/target.npy', target)\n",
    "np.save('../data/processed/numerical_data.npy', numerical_data_new)\n",
    "np.save('../data/processed/standardized_data.npy', standardized_data_new)\n",
    "# Cập nhật ma trận tương quan với đặc trưng mới\n",
    "correlation_matrix_new = np.corrcoef(numerical_data_new, rowvar=False)\n",
    "np.save('../data/processed/correlation_matrix.npy', correlation_matrix_new)\n",
    "\n",
    "# Lưu tên đặc trưng\n",
    "feature_names = [header[idx] for idx in numerical_features]\n",
    "feature_names.append('Avg_Transaction_Value') # Thêm tên đặc trưng mới 1\n",
    "feature_names.append('Trans_to_Limit_Ratio')  # Thêm tên đặc trưng mới 2\n",
    "feature_names.append('Gender')\n",
    "feature_names.extend([f'Education_{cls}' for cls in education_classes])\n",
    "feature_names.extend([f'Marital_{cls}' for cls in marital_classes])\n",
    "feature_names.extend([f'Income_{cls}' for cls in income_classes])\n",
    "feature_names.extend([f'Card_{cls}' for cls in card_classes])\n",
    "\n",
    "# Cập nhật tên đặc trưng số\n",
    "numerical_feature_names = [header[idx] for idx in numerical_features]\n",
    "numerical_feature_names.append('Avg_Transaction_Value')\n",
    "numerical_feature_names.append('Trans_to_Limit_Ratio')\n",
    "\n",
    "np.save('../data/processed/feature_names.npy', np.array(feature_names, dtype=object))\n",
    "np.save('../data/processed/numerical_feature_names.npy', np.array(numerical_feature_names, dtype=object))\n",
    "\n",
    "print(\"\\n✓ Dữ liệu đã xử lý được lưu vào thư mục '../data/processed/'\")\n",
    "print(\"  - features.npy: Ma trận đặc trưng cuối cùng\")\n",
    "print(\"  - target.npy: Biến mục tiêu (nhãn churn)\")\n",
    "print(\"  - numerical_data.npy: Đặc trưng số gốc (đã cập nhật)\")\n",
    "print(\"  - standardized_data.npy: Đặc trưng số đã tiêu chuẩn hóa (đã cập nhật)\")\n",
    "print(\"  - correlation_matrix.npy: Ma trận tương quan (đã cập nhật)\")\n",
    "print(\"  - feature_names.npy: Tên đặc trưng (đã cập nhật)\")\n",
    "print(\"  - numerical_feature_names.npy: Tên đặc trưng số (đã cập nhật)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
